{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing a bit with the data before writing a proper utils file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_params_for_file(filepath):\n",
    "    \"\"\"\n",
    "    Parses camera parameters from a given RealEstate10K file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path for the txt file.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - video_url (str): URL of the video.\n",
    "            - K (torch.Tensor): 3x3 camera intrinsics matrix.\n",
    "            - timestamps (list[int]): List of timestamps (in microseconds) for each frame.\n",
    "            - extrinsics (list[torch.Tensor]): List of 3x4 camera extrinsics matrices for each frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # lines is a list of str representing lines from a file, containing\n",
    "    # the video URL, timestamps, camera intrinsics, and extrinsics.\n",
    "    \n",
    "    # video URL\n",
    "    video_url = lines[0].strip()\n",
    "        \n",
    "    # camera intrinsics (done just on first frame since it is constant across time)\n",
    "    first_frame = lines[1].strip().split()\n",
    "    f_x, f_y, c_x, c_y = map(float, first_frame[1:5])\n",
    "    K = torch.tensor([[f_x, 0, c_x],\n",
    "                      [0, f_y, c_y],\n",
    "                      [0, 0, 1]], dtype=torch.float32)\n",
    "    # top left corner of the image is (0, 0) and bottom right corner is (1, 1)\n",
    "    # for an image of size (w, h), the intrinsic matrix has w * f_x, h * f_y, w * c_x, h * c_y\n",
    "    \n",
    "    # timestamps and camera extrinsics\n",
    "    timestamps = []\n",
    "    extrinsics = []\n",
    "    for line in lines[1:]: # skip the first line (video URL)\n",
    "        frame = line.strip().split()\n",
    "        timestamp = int(frame[0])\n",
    "        timestamps.append(timestamp)\n",
    "        P = torch.tensor(list(map(float, frame[7:])), dtype=torch.float32).reshape(3, 4)\n",
    "        extrinsics.append(P)\n",
    "    \n",
    "    return video_url, K, timestamps, extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_directory(directory):\n",
    "    \"\"\"\n",
    "    Parses all RealEstate10K files in a given directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Path for the directory containing txt files.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples where each tuple contains: (video_url, K, timestamps, extrinsics).\n",
    "    \"\"\"\n",
    "    \n",
    "    camera_params = []\n",
    "    \n",
    "    txt_files = [file for file in os.listdir(directory) if file.endswith(\".txt\")]\n",
    "    \n",
    "    for file in tqdm(txt_files, desc=\"Processing RealEstate10K files\", unit=\"file\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, file)\n",
    "            video_url, K, timestamps, extrinsics = get_camera_params_for_file(filepath)\n",
    "            camera_params.append((video_url, K, timestamps, extrinsics))\n",
    "\n",
    "    return camera_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing RealEstate10K files:  24%|██▍       | 1841/7711 [00:03<00:10, 535.33file/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m camera_params_test \u001b[38;5;241m=\u001b[39m \u001b[43mparse_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./../RealEstate10K/RealEstate10K/test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(f\"Number of videos in test set: {len(camera_params_test)}\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mparse_directory\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     18\u001b[0m         filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, file)\n\u001b[1;32m---> 19\u001b[0m         video_url, K, timestamps, extrinsics \u001b[38;5;241m=\u001b[39m \u001b[43mget_camera_params_for_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m         camera_params\u001b[38;5;241m.\u001b[39mappend((video_url, K, timestamps, extrinsics))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m camera_params\n",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m, in \u001b[0;36mget_camera_params_for_file\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m     38\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(frame[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     39\u001b[0m     timestamps\u001b[38;5;241m.\u001b[39mappend(timestamp)\n\u001b[1;32m---> 40\u001b[0m     P \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     extrinsics\u001b[38;5;241m.\u001b[39mappend(P)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m video_url, K, timestamps, extrinsics\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera_params_test = parse_directory(\"./../RealEstate10K/RealEstate10K/test\")\n",
    "# print(f\"Number of videos in test set: {len(camera_params_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera_params_train = parse_directory(\"./../RealEstate10K/RealEstate10K/train\")\n",
    "# print(f\"Number of videos in train set: {len(camera_params_train)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl-ecole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
